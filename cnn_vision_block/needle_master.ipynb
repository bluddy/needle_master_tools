{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NeedleMaster Dataset Example\n",
    "\n",
    "Predict the needle position and orientation from an image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports \n",
    "* pytorch_datasets for Dataset class, DataLoader\n",
    "* tdqm for interactive loading bars \n",
    "* numpy for math \n",
    "* torch for deep learning library\n",
    "* torchvision for deep learning vision library \n",
    "* multiprocessing to run on multiple cpus (if applicable)\n",
    "* random to select random trials/frames in _get__item_, and to make random datasplits\n",
    "* matplotlib for displaying image frames\n",
    "* pdb (debugging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/home/molly/workspace/Utils/pytorch_datasets/')\n",
    "\n",
    "import random \n",
    "import numpy as np\n",
    "from tqdm import tqdm as tdqm\n",
    "import multiprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import patches\n",
    "from pdb import set_trace as woah\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import pytorch_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to set up the environment. Choose if the deep learning will run on the CPU or GPU. Initialize the torch random seed, and if using a GPU the GPU random seed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(random.randint(1, 10000))\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if(DEVICE == \"cuda\"):\n",
    "    torch.cuda.manual_seed(random.randint(1, 10000))\n",
    "    # Disable nondeterministic ops (not sure if critical but better safe than sorry)\n",
    "    torch.backends.cudnn.enabled = False  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "This notebook is an example for using the Pytorch Datasets wrapper to write a data loader for the NeedleMaster dataset. \n",
    "\n",
    "* __NeedleMaster__ is an Android game developped by Chris Paxton (https://github.com/cpaxton/needle_master_tools.) Images from recorded demonstrations were rendered to create a toy dataset with images, needle poses, and user actions. This dataset is currently on a local directory. For information contact molly@jhu.edu. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nm = pytorch_datasets.NeedleMaster('/home/molly/workspace/Surgical_Automation/experiments/needle_master_tools/', \\\n",
    "                                   train_split=None, transforms=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The attribute '_getitem_' can be used to load individual images and needle poses. The needle position is x/screen_width, y/screen_width, and theta/2_pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "% matplotlib notebook\n",
    "sample = nm.__getitem__()#idx=100, frame_idx=10)\n",
    "\n",
    "plt.imshow(sample['image'])\n",
    "#plt.scatter(sample['needle'][0]*500 + 80, sample['needle'][1]*370 + 60, c='r')\n",
    "plt.show()\n",
    "\n",
    "print('needle pose: ' + str(sample['needle']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.Compose([\n",
    "    #torchvision.transforms.ToPILImage(),\n",
    "    torchvision.transforms.Resize(256),\n",
    "    torchvision.transforms.RandomCrop((224, 224)),\n",
    "#     torchvision.transforms.RandomRotation(30),\n",
    "#     torchvision.transforms.ColorJitter(.2, .2, .2, .2), \n",
    "#     torchvision.transforms.ToTensor(),\n",
    "#     torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toPIL = torchvision.transforms.ToPILImage()\n",
    "transform(toPIL(sample['image']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_to_numpy_im(image):\n",
    "    C, W, H = image.size()\n",
    "    numpy_image = np.zeros((W, H, C))\n",
    "    for c in range(C):\n",
    "        numpy_image[:,:,c] = image[c,:,:].numpy()\n",
    "    return numpy_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model \n",
    "A pretrained resnet18 model is used with a final fully connected layer. The FC layer is used to regress the pose of the needle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class resnet18(torch.nn.Module):\n",
    "    \"\"\" Example Model. ResNet18 with a regression layer on top. \"\"\"\n",
    "    def __init__(self, num_labels):\n",
    "        super(Model, self).__init__()\n",
    "        self.base_model = torch.nn.Sequential(*list(torchvision.models.resnet18(pretrained=True).children())[:-1])\n",
    "        base_model_fc_size = list(self.base_model.parameters())[-1].size(0)\n",
    "        self.fc = torch.nn.Linear(base_model_fc_size, num_labels)\n",
    "        self.sm = torch.nn.Softmax()\n",
    "        \n",
    "    def forward(self, images):\n",
    "        im_features = self.base_model(images)\n",
    "        preds = self.fc(im_features.squeeze())\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cnn3(torch.nn.Module):\n",
    "    \"\"\" small network trained from scratch\"\"\"\n",
    "    def __init__(self, side_len, num_labels):\n",
    "        super(cnn4, self).__init__()\n",
    "        # convolutional layers \n",
    "        self.conv1 = torch.nn.Conv2d(3,   5, 5, stride=2, padding=True)\n",
    "        self.conv2 = torch.nn.Conv2d(5,  10, 5, stride=4, padding=True)\n",
    "        self.conv3 = torch.nn.Conv2d(10, 20, 5, stride=4, padding=True)\n",
    "        self.relu  = torch.nn.ReLU()\n",
    "        \n",
    "        self.fc1 = torch.nn.Linear(980, 50)\n",
    "        self.fc2 = torch.nn.Linear(50,  num_labels)\n",
    "        self.sm  = torch.nn.Softmax()\n",
    "        \n",
    "    def forward(self, images):\n",
    "        im_size = images.size()\n",
    "        h1 = self.relu(self.conv1(images))\n",
    "        h2 = self.relu(self.conv2(h1))\n",
    "        h3 = self.relu(self.conv3(h2))\n",
    "        \n",
    "        preds = self.fc2(self.fc1(h3.view(im_size[0], -1).squeeze()))\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cnn5(torch.nn.Module):\n",
    "    \"\"\" small network trained from scratch\"\"\"\n",
    "    def __init__(self, side_len, n_classes, num_labels, mode='regress'):\n",
    "        super(cnn5, self).__init__()\n",
    "        # convolutional layers \n",
    "        self.conv1 = torch.nn.Conv2d(3,   5, 5, padding=True)\n",
    "        self.conv2 = torch.nn.Conv2d(5,  10, 5, padding=True)\n",
    "        self.conv3 = torch.nn.Conv2d(10, 20, 5, padding=True)\n",
    "        self.conv4 = torch.nn.Conv2d(20, 30, 5, padding=True)\n",
    "        self.conv5 = torch.nn.Conv2d(30, 40, 5, padding=True)\n",
    "        self.pool  = torch.nn.AvgPool2d(2, stride=2)\n",
    "        self.relu  = torch.nn.ReLU()\n",
    "        \n",
    "        self.mode = mode\n",
    "        \n",
    "        if(mode == 'classify'):\n",
    "            self.fc1  = torch.nn.Linear(360, n_classes)\n",
    "        elif(mode == 'regress'):\n",
    "            self.fc1  = torch.nn.Linear(360, num_labels)\n",
    "            \n",
    "        #self.fc2 = torch.nn.Linear(100,  num_labels)\n",
    "        self.sm   = torch.nn.Softmax()\n",
    "        \n",
    "        \n",
    "    def forward(self, images):\n",
    "        im_size = images.size()\n",
    "\n",
    "        h1 = self.relu(self.pool(self.conv1(images)))\n",
    "        h2 = self.relu(self.pool(self.conv2(h1)))\n",
    "        h3 = self.relu(self.pool(self.conv3(h2)))\n",
    "        h4 = self.relu(self.pool(self.conv4(h3)))\n",
    "        h5 = self.relu(self.pool(self.conv5(h4)))\n",
    "        \n",
    "        if(self.mode == 'classify'):\n",
    "            preds = self.fc1(h5.view(im_size[0] , -1).squeeze())\n",
    "            \n",
    "        elif(self.mode == 'regress'):\n",
    "            preds = self.fc1(h5.view(im_size[0], -1).squeeze()) #OPT: add softmax \n",
    "            #preds = self.fc2(self.fc1(h5.view(im_size[0], n_classes, -1).squeeze()))\n",
    "            \n",
    "        return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Epoch\n",
    "Code to do one epoch of training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch(train_mode, description, model, dataloader, optimizer=None, loss_func=None):\n",
    "    \"\"\" Train, validation, or test epoch \"\"\"\n",
    "    # Create dataset iterator\n",
    "    #iterator = tqdm(dataloader, ncols=115, desc=description)\n",
    "\n",
    "    # Turn off batch norm, etc. during testing/validation\n",
    "    model = model.train(train_mode)\n",
    "\n",
    "    # Data to print\n",
    "    running_losses, running_predict, running_x, running_y, running_w = [], [], [], [], []\n",
    "\n",
    "    # Loop over all data\n",
    "    with torch.set_grad_enabled(train_mode):\n",
    "        for data in dataloader:\n",
    "            outputs = model(data['image'].to(DEVICE))# Forward pass\n",
    "            #woah()\n",
    "            if train_mode:\n",
    "                optimizer.zero_grad() # Zero out gradients\n",
    "                loss = loss_func(outputs.double(), torch.cuda.LongTensor(data['needle'][:,0].to(DEVICE))) # loss_func(outputs.double(), data['needle'].double().to(DEVICE))#\n",
    "                running_losses.append(loss.item())\n",
    "                                \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "            # Update labels and predictions\n",
    "            prediction = outputs.cpu().detach().numpy()\n",
    "            running_predict.extend(prediction)\n",
    "\n",
    "            # Update accuracy\n",
    "            error_x     = np.mean(abs(data[\"needle\"].numpy()[:,0] - prediction[:,0]))\n",
    "            error_y     = np.mean(abs(data[\"needle\"].numpy()[:,1] - prediction[:,1]))\n",
    "            error_w     = np.mean(abs(data[\"needle\"].numpy()[:,2] - prediction[:,2]))\n",
    "            running_x.append(error_x); running_y.append(error_y); running_w.append(error_w)\n",
    "                          \n",
    "#             info_to_show = {'Error x': \"{:.4f}\".format(error_x)}\n",
    "            \n",
    "#             if train_mode:\n",
    "#                 info_to_show['Loss'] = \"{:.5f}\".format(np.mean(running_losses))\n",
    "#             iterator.set_postfix(info_to_show)\n",
    "    \n",
    "    return running_losses, running_predict, running_x, running_y, running_w, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## main "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODE = 'classify'\n",
    "\n",
    "# Create image tranforms\n",
    "# Create image tranforms\n",
    "transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((224, 224)),\n",
    "    torchvision.transforms.CenterCrop((172,172)),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    \n",
    "])\n",
    "\n",
    "# Create datasets\n",
    "root = '/home/molly/workspace/Surgical_Automation/experiments/needle_master_tools/'\n",
    "dataset_train = pytorch_datasets.NeedleMaster(root, train_split=None, transforms=transforms, discrete=MODE=='classify')\n",
    "\n",
    "# Create dataloaders\n",
    "dataloader_train = torch.utils.data.DataLoader(dataset_train, shuffle=True,  batch_size=256,  num_workers=multiprocessing.cpu_count())\n",
    "\n",
    "# Create Model\n",
    "regress_dim = 3\n",
    "n_classes   = 10\n",
    "model       = cnn5(224, n_classes, regress_dim, mode=MODE).to(DEVICE)\n",
    "\n",
    "# Create loss function and optimizer\n",
    "optimizer = torch.optim.Adam([p for p in model.parameters() if p.requires_grad], lr=0.001)\n",
    "\n",
    "if(MODE=='regress'):\n",
    "    loss_func = torch.nn.MSELoss().to(DEVICE)\n",
    "elif(MODE=='classify'):\n",
    "    loss_func = torch.nn.CrossEntropyLoss().to(DEVICE)\n",
    "\n",
    "# Train + Val\n",
    "Loss, Error_x, Error_y, Error_w = [], [], [], []\n",
    "num_epochs = 20\n",
    "for epoch_idx in range(num_epochs):\n",
    "    loss, pred, e_x, e_y, e_w, model = epoch(True, \"Training\", model, dataloader_train, optimizer, loss_func)\n",
    "    Loss.extend(loss); Error_x.extend(e_x); Error_y.extend(e_y); Error_w.extend(e_w)\n",
    "    #epoch(False, \"Validating\", model, dataloader_val)\n",
    "    print(\"Epoch: \" + str(epoch_idx) + \"    Loss: \"+ \"%1.2f\" % np.mean(loss) +\"\\t Error_x: \"+ \"%1.2f\" % np.mean(e_x) , end='\\r')\n",
    "# Test\n",
    "#epoch(False, \"Testing\", model, dataloader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()#figsize=(10,5))\n",
    "plt.plot(Loss, 'k--', label='Loss')\n",
    "plt.plot(Error_x, c='r', label='Error x')\n",
    "plt.plot(Error_y, c='b', label='Error y')\n",
    "plt.plot(Error_w, c='g', label='Error w')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(10,5))\n",
    "# plt.plot(np.multiply(Error_x, 1920.0), c='r', label='Error x [pixels]')\n",
    "# plt.plot(np.multiply(Error_y, 1080.0), c='b', label='Error y [pixels]')\n",
    "# # plt.plot(Error_w*2*3.1415, c='g', label='Error w [radians]')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create image tranforms\n",
    "transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((224, 224)),\n",
    "    torchvision.transforms.CenterCrop((172,172)),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    \n",
    "])\n",
    "\n",
    "# Create datasets\n",
    "root = '/home/molly/workspace/Surgical_Automation/experiments/needle_master_tools/'\n",
    "dataset = pytorch_datasets.NeedleMaster(root, train_split=None, transforms=transforms, discrete=MODE=='classify')\n",
    "# Create dataloaders\n",
    "dataloader = torch.utils.data.DataLoader(dataset, shuffle=True,  batch_size=256,  num_workers=multiprocessing.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_size = 172\n",
    "\n",
    "for dat in dataloader:\n",
    "    outputs = model(dat['image'].to(DEVICE))\n",
    "    prediction = outputs.cpu().detach().numpy()\n",
    "    \n",
    "    for idx in range(10):\n",
    "        fig = plt.figure()\n",
    "        im = dat['image'][idx,:, :, :].reshape(172, 172, 3)\n",
    "        plt.imshow(dat['image'][idx,0, :, :])        \n",
    "        \n",
    "        if(MODE == 'regress'): # show where we predicted the needle to be \n",
    "            plt.scatter(dat['needle'][idx][0]*edge_size, dat['needle'][idx][1]*edge_size, c='r')\n",
    "            plt.scatter(prediction[idx,0]*edge_size, prediction[idx,1]*edge_size, c='b')\n",
    "            \n",
    "        elif(MODE == 'classify'):\n",
    "            class_pred = np.argmax(prediction[idx,:])\n",
    "            \n",
    "            shape = patches.Polygon([[np.int(np.floor(class_pred/10.0 * edge_size)), 0], \\\n",
    "                            [np.int(np.floor((class_pred+1)/10.0 * edge_size)), 0], \\\n",
    "                            [np.int(np.floor((class_pred+1)/10.0 * edge_size)), edge_size], \n",
    "                            [np.int(np.floor(class_pred/10.0 * edge_size)), edge_size]], color='r', alpha=0.4)\n",
    "            plt.gca().add_patch(shape)\n",
    "            \n",
    "            \n",
    "        plt.show()\n",
    "\n",
    "        print('needle pose: ' + str(dat['needle'][idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About this notebook\n",
    "Created on 2/13/2019. Original code from surgical_activity_recognition.py by Mike Peven. Modified by Molly O'Brien. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Footer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(pred, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
