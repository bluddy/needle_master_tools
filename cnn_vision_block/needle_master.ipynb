{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NeedleMaster Dataset Example\n",
    "\n",
    "Predict the needle position and orientation from an image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports \n",
    "* pytorch_datasets for Dataset class, DataLoader\n",
    "* tdqm for interactive loading bars \n",
    "* numpy for math \n",
    "* torch for deep learning library\n",
    "* torchvision for deep learning vision library \n",
    "* multiprocessing to run on multiple cpus (if applicable)\n",
    "* random to select random trials/frames in _get__item_, and to make random datasplits\n",
    "* matplotlib for displaying image frames\n",
    "* pdb (debugging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/home/molly/workspace/Utils/pytorch_datasets/')\n",
    "\n",
    "import random \n",
    "import numpy as np\n",
    "from tqdm import tqdm as tdqm\n",
    "import multiprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import patches\n",
    "from pdb import set_trace as woah\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import pytorch_datasets\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to set up the environment. Choose if the deep learning will run on the CPU or GPU. Initialize the torch random seed, and if using a GPU the GPU random seed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(random.randint(1, 10000))\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "if(DEVICE == \"cuda:0\"):\n",
    "    torch.cuda.manual_seed(random.randint(1, 10000))\n",
    "    # Disable nondeterministic ops (not sure if critical but better safe than sorry)\n",
    "    torch.backends.cudnn.enabled = False  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "This notebook is an example for using the Pytorch Datasets wrapper to write a data loader for the NeedleMaster dataset. \n",
    "\n",
    "* __NeedleMaster__ is an Android game developped by Chris Paxton (https://github.com/cpaxton/needle_master_tools.) Images from recorded demonstrations were rendered to create a toy dataset with images, needle poses, and user actions. This dataset is currently on a local directory. For information contact molly@jhu.edu. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENVIRONMENT = '17'\n",
    "\n",
    "nm = pytorch_datasets.NeedleFrames('/home/molly/workspace/Surgical_Automation/experiments/needle_master_tools/', \\\n",
    "                                   environment=ENVIRONMENT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The attribute '_getitem_' can be used to load individual images and needle poses. If discrete=False, The needle position is x/screen_width, y/screen_width, and theta/2_pi. Otherwise the needle position is which 1/10 region the x, y, z is in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "sample = nm.__getitem__()#idx=100, frame_idx=10)\n",
    "\n",
    "plt.imshow(sample['image'])\n",
    "#plt.scatter(sample['needle'][0]*500 + 80, sample['needle'][1]*370 + 60, c='r')\n",
    "plt.show()\n",
    "\n",
    "print('needle pose: ' + str(sample['needle']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the mean and std of the image channels\n",
    "Use this data to normalize later. (Note, make sure that ENVIRONMENT is the env you want to use later, otherwise the means/stds won't be useful)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create datasets\n",
    "transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((224, 224)),\n",
    "    torchvision.transforms.CenterCrop((172,172)),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "       \n",
    "])\n",
    "\n",
    "root = '/home/molly/workspace/Surgical_Automation/experiments/needle_master_tools/'\n",
    "dataset = pytorch_datasets.NeedleFrames(root, transforms=transforms, environment=ENVIRONMENT)\n",
    "# Create dataloaders\n",
    "dataloader = torch.utils.data.DataLoader(dataset, shuffle=True,  batch_size=100,  num_workers=multiprocessing.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = []; varz = []; batch_size = []\n",
    "\n",
    "for dat in dataloader: \n",
    "    mean = [dat['image'][:,0,:,:].mean(), dat['image'][:,1,:,:].mean(), dat['image'][:,2,:,:].mean()]\n",
    "    var  = [dat['image'][:,0,:,:].std()**2,  dat['image'][:,1,:,:].std()**2,  dat['image'][:,2,:,:].std()**2]\n",
    "    \n",
    "    means.append(mean); varz.append(var); batch_size.append(dat['image'].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mean = np.mean(np.array(means), axis=0)\n",
    "data_std  = np.sqrt(np.mean(np.array(varz), axis=0))\n",
    "print(data_mean)\n",
    "print(data_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model \n",
    "A pretrained resnet18 model is used with a final fully connected layer. The FC layer is used to regress the pose of the needle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class resnet18(torch.nn.Module):\n",
    "    \"\"\" Example Model. ResNet18 with a regression layer on top. \"\"\"\n",
    "    def __init__(self, side_len, n_classes, num_labels, mode='regress'):\n",
    "        super(resnet18, self).__init__()\n",
    "        self.base_model = torch.nn.Sequential(*list(torchvision.models.resnet18(pretrained=True).children())[:-1])\n",
    "        base_model_fc_size = list(self.base_model.parameters())[-1].size(0)\n",
    "        if(mode == 'regress'):\n",
    "            self.fc = torch.nn.Linear(base_model_fc_size, num_labels)\n",
    "        elif(mode == 'classify'):\n",
    "            self.fc = torch.nn.Linear(base_model_fc_size, n_classes)\n",
    "        self.sm = torch.nn.Softmax()\n",
    "        \n",
    "    def forward(self, images):\n",
    "        im_features = self.base_model(images)\n",
    "        preds = self.fc(im_features.squeeze())\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cnn3(torch.nn.Module):\n",
    "    \"\"\" small network trained from scratch\"\"\"\n",
    "    def __init__(self, n_classes, num_labels, mode='regress'):\n",
    "        super(cnn3, self).__init__()\n",
    "        # convolutional layers \n",
    "        self.conv1 = torch.nn.Conv2d(3,   5, 5, stride=2)\n",
    "        self.conv2 = torch.nn.Conv2d(5,  10, 5, stride=2)\n",
    "        self.conv3 = torch.nn.Conv2d(10, 20, 5, stride=2)\n",
    "        self.relu  = torch.nn.ReLU()\n",
    "        \n",
    "        self.mode = mode\n",
    "        \n",
    "        if(mode == 'classify'):\n",
    "            self.fc1  = torch.nn.Linear(6480, n_classes)\n",
    "        elif(mode == 'regress'):\n",
    "            self.fc1  = torch.nn.Linear(6480, num_labels)\n",
    "            \n",
    "        self.sm  = torch.nn.Softmax()\n",
    "        \n",
    "    def forward(self, images):\n",
    "        im_size = images.shape\n",
    "        h1 = self.relu(self.conv1(images))\n",
    "        h2 = self.relu(self.conv2(h1))\n",
    "        h3 = self.relu(self.conv3(h2))\n",
    "        \n",
    "        preds = self.fc1(h3.view(im_size[0], -1).squeeze())\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cnn5(torch.nn.Module):\n",
    "    \"\"\" small network trained from scratch\"\"\"\n",
    "    def __init__(self, n_classes, num_labels, mode='regress'):\n",
    "        super(cnn5, self).__init__()\n",
    "        # convolutional layers \n",
    "        self.conv1 = torch.nn.Conv2d(3,   5, 5, padding=True)\n",
    "        self.conv2 = torch.nn.Conv2d(5,  10, 5, padding=True)\n",
    "        self.conv3 = torch.nn.Conv2d(10, 20, 5, padding=True)\n",
    "        self.conv4 = torch.nn.Conv2d(20, 30, 5, padding=True)\n",
    "        self.conv5 = torch.nn.Conv2d(30, 40, 5, padding=True)\n",
    "        self.pool  = torch.nn.AvgPool2d(2, stride=2)\n",
    "        #self.relu  = torch.nn.ReLU()\n",
    "        \n",
    "        self.mode = mode\n",
    "        \n",
    "        if(mode == 'classify'):\n",
    "            self.fc1  = torch.nn.Linear(360, n_classes)\n",
    "        elif(mode == 'regress'):\n",
    "            self.fc1  = torch.nn.Linear(360, num_labels)\n",
    "            \n",
    "        #self.fc2 = torch.nn.Linear(100,  num_labels)\n",
    "        self.sm   = torch.nn.Softmax()\n",
    "        \n",
    "        \n",
    "    def forward(self, images):\n",
    "        im_size = images.size()\n",
    "\n",
    "        h1 = F.relu(self.pool(self.conv1(images)))\n",
    "        h2 = F.relu(self.pool(self.conv2(h1)))\n",
    "        h3 = F.relu(self.pool(self.conv3(h2)))\n",
    "        h4 = F.relu(self.pool(self.conv4(h3)))\n",
    "        h5 = F.relu(self.pool(self.conv5(h4)))\n",
    "        \n",
    "        if(self.mode == 'classify'):\n",
    "            preds = self.fc1(h5.view(im_size[0] , -1).squeeze())\n",
    "            \n",
    "        elif(self.mode == 'regress'):\n",
    "            preds = self.fc1(h5.view(im_size[0], -1).squeeze()) #OPT: add softmax \n",
    "            #preds = self.fc2(self.fc1(h5.view(im_size[0], n_classes, -1).squeeze()))\n",
    "            \n",
    "        return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Epoch\n",
    "Code to do one epoch of training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch(train_mode, description, model, dataloader, optimizer=None, loss_func=None):\n",
    "    \"\"\" Train, validation, or test epoch \"\"\"\n",
    "    # Create dataset iterator\n",
    "    #iterator = tqdm(dataloader, ncols=115, desc=description)\n",
    "\n",
    "    # Turn off batch norm, etc. during testing/validation\n",
    "    model = model.train(train_mode)\n",
    "\n",
    "    # Data to print\n",
    "    running_losses, running_predict, running_x, running_y, running_w = [], [], [], [], []\n",
    "\n",
    "    # Loop over all data\n",
    "    with torch.set_grad_enabled(train_mode):\n",
    "        for data in dataloader:\n",
    "            outputs = model(data['image'].to(DEVICE))# Forward pass\n",
    "            \n",
    "            if train_mode:\n",
    "                optimizer.zero_grad() # Zero out gradients\n",
    "                ## Regress\n",
    "                if(model.mode == 'regress'):\n",
    "                    loss = loss_func(outputs.double(), data['needle'].double().to(DEVICE))#\n",
    "                \n",
    "                ## Classify\n",
    "                elif(model.mode == 'classify'):\n",
    "                    loss = loss_func(outputs.double(), torch.cuda.LongTensor(data['needle'][:,0].to(DEVICE))) # \n",
    "                \n",
    "                running_losses.append(loss.detach().item())\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "            # Update labels and predictions\n",
    "            if(model.mode == 'regress'):\n",
    "                prediction = outputs.cpu().detach().numpy()\n",
    "                error_x     = np.mean(abs(data[\"needle\"].numpy()[:,0] - prediction[:,0]))\n",
    "                error_y     = np.mean(abs(data[\"needle\"].numpy()[:,1] - prediction[:,1]))\n",
    "                error_w     = np.mean(abs(data[\"needle\"].numpy()[:,2] - prediction[:,2]))\n",
    "                \n",
    "            elif(model.mode == 'classify'):\n",
    "                prediction = np.argmax(outputs.cpu().detach().numpy(), axis=1)\n",
    "                error_x     = np.mean(abs(data[\"needle\"].numpy()[:,0] - prediction))\n",
    "                error_y     = -0.1 # NOTE: we're only predicting x so no y error\n",
    "                error_w     = -0.1 # NOTE: we're only predicting x so no z error\n",
    "                \n",
    "            running_predict.extend(prediction)\n",
    "\n",
    "            # Update accuracy\n",
    "            \n",
    "            running_x.append(error_x); running_y.append(error_y); running_w.append(error_w)\n",
    "                          \n",
    "#             info_to_show = {'Error x': \"{:.4f}\".format(error_x)}\n",
    "            \n",
    "#             if train_mode:\n",
    "#                 info_to_show['Loss'] = \"{:.5f}\".format(np.mean(running_losses))\n",
    "#             iterator.set_postfix(info_to_show)\n",
    "    \n",
    "    return running_losses, running_predict, running_x, running_y, running_w, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## main "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODE = 'classify'\n",
    "\n",
    "# Create image tranforms\n",
    "transforms_train = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((224, 224)),\n",
    "    torchvision.transforms.CenterCrop((172,172)),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(mean=data_mean, std=data_std),\n",
    "    \n",
    "])\n",
    "\n",
    "# Create datasets\n",
    "root = '/home/molly/workspace/Surgical_Automation/experiments/needle_master_tools/'\n",
    "dataset_train = pytorch_datasets.NeedleFrames(root, environment=ENVIRONMENT, transforms=transforms_train, \\\n",
    "                                              discrete=MODE=='classify')\n",
    "\n",
    "# Create dataloaders\n",
    "dataloader_train = torch.utils.data.DataLoader(dataset_train, shuffle=True,  batch_size=256,  \\\n",
    "                                               num_workers=multiprocessing.cpu_count())\n",
    "\n",
    "# Create Model\n",
    "regress_dim = 3\n",
    "n_classes   = 10\n",
    "model       = cnn3(n_classes, regress_dim, mode=MODE).to(DEVICE)\n",
    "\n",
    "# Create loss function and optimizer\n",
    "optimizer = torch.optim.Adam([p for p in model.parameters() if p.requires_grad], lr=0.0001)\n",
    "\n",
    "if(MODE=='regress'):\n",
    "    loss_func = torch.nn.MSELoss().to(DEVICE)\n",
    "elif(MODE=='classify'):\n",
    "    loss_func = torch.nn.CrossEntropyLoss().to(DEVICE)\n",
    "\n",
    "# Train + Val\n",
    "Loss, Error_x, Error_y, Error_w = [], [], [], []\n",
    "num_epochs = 5\n",
    "for epoch_idx in range(num_epochs):\n",
    "    loss, pred, e_x, e_y, e_w, model = epoch(True, \"Training\", model, dataloader_train, optimizer, loss_func)\n",
    "    Loss.extend(loss); Error_x.extend(e_x); Error_y.extend(e_y); Error_w.extend(e_w)\n",
    "    #epoch(False, \"Validating\", model, dataloader_val)\n",
    "    print(\"Epoch: \" + str(epoch_idx) + \"    Loss: \"+ \"%1.2f\" % np.mean(loss) + \\\n",
    "          \"\\t Error_x: \"+ \"%1.2f\" % np.mean(e_x) , end='\\r')\n",
    "# Test\n",
    "#epoch(False, \"Testing\", model, dataloader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()#figsize=(10,5))\n",
    "plt.plot(Loss, 'k--', label='Loss')\n",
    "plt.plot(Error_x, c='r', label='Error x')\n",
    "plt.plot(Error_y, c='b', label='Error y')\n",
    "plt.plot(Error_w, c='g', label='Error w')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the stats of the test environment\n",
    "test_environment = '14'\n",
    "\n",
    "root = '/home/molly/workspace/Surgical_Automation/experiments/needle_master_tools/'\n",
    "test_dataset = pytorch_datasets.NeedleFrames(root, environment=test_environment,\\\n",
    "                                             discrete=MODE=='classify')\n",
    "# Create dataloaders\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, shuffle=True,  batch_size=100, \\\n",
    "                                              num_workers=multiprocessing.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_means = []; test_varz = []; test_batch_size = []\n",
    "\n",
    "for dat in test_dataloader: \n",
    "    mean = [dat['image'][:,0,:,:].mean(), dat['image'][:,1,:,:].mean(), dat['image'][:,2,:,:].mean()]\n",
    "    var  = [dat['image'][:,0,:,:].std()**2,  dat['image'][:,1,:,:].std()**2,  dat['image'][:,2,:,:].std()**2]\n",
    "    \n",
    "    test_means.append(mean); test_varz.append(var); test_batch_size.append(dat['image'].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_mean = np.mean(np.array(test_means), axis=0)\n",
    "test_data_std  = np.sqrt(np.mean(np.array(test_varz), axis=0))\n",
    "print(test_data_mean)\n",
    "print(test_data_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create datasets\n",
    "test_transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((224, 224)),\n",
    "    torchvision.transforms.CenterCrop((172,172)),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(mean=test_data_mean, std=test_data_std),\n",
    "       \n",
    "])\n",
    "\n",
    "root = '/home/molly/workspace/Surgical_Automation/experiments/needle_master_tools/'\n",
    "test_dataset = pytorch_datasets.NeedleFrames(root, transforms=test_transforms, environment=test_environment,\\\n",
    "                                             discrete=MODE=='classify')\n",
    "# Create dataloaders\n",
    "test_dataloader = torch.utils.data.DataLoader(dataset, shuffle=True,  batch_size=100, \\\n",
    "                                              num_workers=multiprocessing.cpu_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_size = 172\n",
    "num_batches = 0\n",
    "\n",
    "for dat in test_dataloader:\n",
    "    \n",
    "    num_batches = num_batches + 1\n",
    "    outputs = model(dat['image'].to(DEVICE))\n",
    "    prediction = outputs.cpu().detach().numpy()\n",
    "    \n",
    "    for idx in range(10):\n",
    "        fig = plt.figure()\n",
    "        torch_im = dat['image'][idx,:, :, :].permute(1,2,0).cpu().detach().numpy()\n",
    "        im = np.multiply(torch_im, test_data_std) + test_data_mean\n",
    "        plt.imshow(im)        \n",
    "        \n",
    "        if(MODE == 'regress'): # show where we predicted the needle to be \n",
    "            plt.scatter(dat['needle'][idx][0]*edge_size, dat['needle'][idx][1]*edge_size, c='r')\n",
    "            plt.scatter(prediction[idx,0]*edge_size, prediction[idx,1]*edge_size, c='b')\n",
    "                        \n",
    "        elif(MODE == 'classify'):\n",
    "            class_pred = np.argmax(prediction[idx,:])\n",
    "            \n",
    "            shape = patches.Polygon([[np.int(np.floor(class_pred/10.0 * edge_size)), 0], \\\n",
    "                            [np.int(np.floor((class_pred+1)/10.0 * edge_size)), 0], \\\n",
    "                            [np.int(np.floor((class_pred+1)/10.0 * edge_size)), edge_size], \n",
    "                            [np.int(np.floor(class_pred/10.0 * edge_size)), edge_size]], color='w', alpha=0.4)\n",
    "            plt.gca().add_patch(shape)\n",
    "            \n",
    "            \n",
    "        plt.show()\n",
    "        \n",
    "        print('needle pose: ' + str(dat['needle'][idx]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute prediction error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_size = 172\n",
    "num_batches = 0\n",
    "\n",
    "euclidean_error = []\n",
    "class_preds = []\n",
    "true_labels = []\n",
    "for dat in dataloader:\n",
    "    \n",
    "    num_batches = num_batches + 1\n",
    "    outputs = model(dat['image'].to(DEVICE))\n",
    "    prediction = outputs.cpu().detach().numpy()\n",
    "    \n",
    "    for idx in range(len(prediction)):\n",
    "        if(MODE == 'regress'): # show where we predicted the needle to be \n",
    "            euc_err = np.linalg.norm(np.array([dat['needle'][idx][0]*edge_size, dat['needle'][idx][1]*edge_size]) - \\\n",
    "                                    np.array([prediction[idx,0]*edge_size, prediction[idx,1]*edge_size]))\n",
    "            euclidean_error.append(euc_err)\n",
    "            \n",
    "        elif(MODE == 'classify'):\n",
    "            class_pred = np.argmax(prediction[idx,:])\n",
    "            class_preds.append(class_pred)\n",
    "            true_labels.append(dat['needle'][idx][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.array(true_labels) == np.array(class_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.hist(prediction[:,0])\n",
    "plt.xlim([0,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About this notebook\n",
    "Created on 2/13/2019. Original code from surgical_activity_recognition.py by Mike Peven. Modified by Molly O'Brien. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Footer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
