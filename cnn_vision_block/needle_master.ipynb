{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NeedleMaster Dataset Example\n",
    "\n",
    "Predict the needle position and orientation from an image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports \n",
    "* pytorch_datasets for Dataset class, DataLoader\n",
    "* tdqm for interactive loading bars \n",
    "* numpy for math \n",
    "* torch for deep learning library\n",
    "* torchvision for deep learning vision library \n",
    "* multiprocessing to run on multiple cpus (if applicable)\n",
    "* random to select random trials/frames in _get__item_, and to make random datasplits\n",
    "* matplotlib for displaying image frames\n",
    "* pdb (debugging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/home/molly/workspace/Utils/pytorch_datasets/')\n",
    "\n",
    "import random \n",
    "import numpy as np\n",
    "from tqdm import tqdm as tdqm\n",
    "import multiprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from pdb import set_trace as woah\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import pytorch_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to set up the environment. Choose if the deep learning will run on the CPU or GPU. Initialize the torch random seed, and if using a GPU the GPU random seed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(random.randint(1, 10000))\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if(DEVICE == \"cuda\"):\n",
    "    torch.cuda.manual_seed(random.randint(1, 10000))\n",
    "    # Disable nondeterministic ops (not sure if critical but better safe than sorry)\n",
    "    torch.backends.cudnn.enabled = False  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "This notebook is an example for using the Pytorch Datasets wrapper to write a data loader for the NeedleMaster dataset. \n",
    "\n",
    "* __NeedleMaster__ is an Android game developped by Chris Paxton (https://github.com/cpaxton/needle_master_tools.) Images from recorded demonstrations were rendered to create a toy dataset with images, needle poses, and user actions. This dataset is currently on a local directory. For information contact molly@jhu.edu. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nm = pytorch_datasets.NeedleMaster('/home/molly/workspace/Surgical_Automation/experiments/needle_master_tools/', \\\n",
    "                                   train_split=None, transforms=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The attribute '_getitem_' can be used to load individual images and needle poses. The needle position is x/screen_width, y/screen_width, and theta/2_pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support.' +\n",
       "              'Please try Chrome, Safari or Firefox â‰¥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option)\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width, fig.canvas.height);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to  previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overriden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        event.shiftKey = false;\n",
       "        // Send a \"J\" for go to next cell\n",
       "        event.which = 74;\n",
       "        event.keyCode = 74;\n",
       "        manager.command_mode();\n",
       "        manager.handle_keydown(event);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id='79337d1b-8df0-4bc7-969f-4f5885dafa84'></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "needle pose: [ 0.17842301  0.32555237  0.85363978]\n"
     ]
    }
   ],
   "source": [
    "% matplotlib notebook\n",
    "sample = nm.__getitem__(idx=100, frame_idx=100)\n",
    "\n",
    "plt.imshow(sample['image'])\n",
    "#plt.scatter(sample['needle'][0]*500 + 80, sample['needle'][1]*370 + 60, c='r')\n",
    "plt.show()\n",
    "\n",
    "print('needle pose: ' + str(sample['needle']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.Compose([\n",
    "    #torchvision.transforms.ToPILImage(),\n",
    "    torchvision.transforms.Resize(256),\n",
    "    torchvision.transforms.RandomCrop((224, 224)),\n",
    "#     torchvision.transforms.RandomRotation(30),\n",
    "#     torchvision.transforms.ColorJitter(.2, .2, .2, .2), \n",
    "#     torchvision.transforms.ToTensor(),\n",
    "#     torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOAAAADgCAIAAACVT/22AAAZ4klEQVR4nO2dSXNbyZaYT+adMIMk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\nCWUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=224x224 at 0x7FB434B60B38>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toPIL = torchvision.transforms.ToPILImage()\n",
    "transform(toPIL(sample['image']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_to_numpy_im(image):\n",
    "    C, W, H = image.size()\n",
    "    numpy_image = np.zeros((W, H, C))\n",
    "    for c in range(C):\n",
    "        numpy_image[:,:,c] = image[c,:,:].numpy()\n",
    "    return numpy_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model \n",
    "A pretrained resnet18 model is used with a final fully connected layer. The FC layer is used to regress the pose of the needle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class resnet18(torch.nn.Module):\n",
    "    \"\"\" Example Model. ResNet18 with a regression layer on top. \"\"\"\n",
    "    def __init__(self, num_labels):\n",
    "        super(Model, self).__init__()\n",
    "        self.base_model = torch.nn.Sequential(*list(torchvision.models.resnet18(pretrained=True).children())[:-1])\n",
    "        base_model_fc_size = list(self.base_model.parameters())[-1].size(0)\n",
    "        self.fc = torch.nn.Linear(base_model_fc_size, num_labels)\n",
    "        self.sm = torch.nn.Softmax()\n",
    "        \n",
    "    def forward(self, images):\n",
    "        im_features = self.base_model(images)\n",
    "        preds = self.fc(im_features.squeeze())\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cnn3(torch.nn.Module):\n",
    "    \"\"\" small network trained from scratch\"\"\"\n",
    "    def __init__(self, side_len, num_labels):\n",
    "        super(cnn4, self).__init__()\n",
    "        # convolutional layers \n",
    "        self.conv1 = torch.nn.Conv2d(3,   5, 5, stride=2, padding=True)\n",
    "        self.conv2 = torch.nn.Conv2d(5,  10, 5, stride=4, padding=True)\n",
    "        self.conv3 = torch.nn.Conv2d(10, 20, 5, stride=4, padding=True)\n",
    "        self.relu  = torch.nn.ReLU()\n",
    "        \n",
    "        self.fc1 = torch.nn.Linear(980, 50)\n",
    "        self.fc2 = torch.nn.Linear(50,  num_labels)\n",
    "        self.sm  = torch.nn.Softmax()\n",
    "        \n",
    "    def forward(self, images):\n",
    "        im_size = images.size()\n",
    "        h1 = self.relu(self.conv1(images))\n",
    "        h2 = self.relu(self.conv2(h1))\n",
    "        h3 = self.relu(self.conv3(h2))\n",
    "        \n",
    "        preds = self.fc2(self.fc1(h3.view(im_size[0], -1).squeeze()))\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cnn5(torch.nn.Module):\n",
    "    \"\"\" small network trained from scratch\"\"\"\n",
    "    def __init__(self, side_len, n_classes, num_labels):\n",
    "        super(cnn5, self).__init__()\n",
    "        # convolutional layers \n",
    "        self.conv1 = torch.nn.Conv2d(3,   5, 5, stride=2, padding=True)\n",
    "        self.conv2 = torch.nn.Conv2d(5,  10, 5, stride=2, padding=True)\n",
    "        self.conv3 = torch.nn.Conv2d(10, 20, 5, stride=2, padding=True)\n",
    "        self.conv4 = torch.nn.Conv2d(20, 30, 5, stride=2, padding=True)\n",
    "        self.conv5 = torch.nn.Conv2d(30, 40, 5, stride=2, padding=True)\n",
    "        self.relu  = torch.nn.ReLU()\n",
    "        \n",
    "        self.fc1 = torch.nn.Linear(1440, n_classes)\n",
    "        #self.fc2 = torch.nn.Linear(100,  num_labels)\n",
    "        self.sm  = torch.nn.Softmax()\n",
    "        \n",
    "    def forward(self, images):\n",
    "        im_size = images.size()\n",
    "        h1 = self.relu(self.conv1(images))\n",
    "        h2 = self.relu(self.conv2(h1))\n",
    "        h3 = self.relu(self.conv3(h2))\n",
    "        h4 = self.relu(self.conv4(h3))\n",
    "        h5 = self.relu(self.conv5(h4))\n",
    "        \n",
    "        #woah()\n",
    "        \n",
    "        \n",
    "        preds = self.fc1(h5.view(im_size[0], -1).squeeze())\n",
    "        #preds = self.fc1(h5.view(im_size[0], n_classes, -1).squeeze())\n",
    "        #preds = self.fc2(self.fc1(h5.view(im_size[0], n_classes, -1).squeeze()))\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Epoch\n",
    "Code to do one epoch of training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch(train_mode, description, model, dataloader, optimizer=None, loss_func=None):\n",
    "    \"\"\" Train, validation, or test epoch \"\"\"\n",
    "    # Create dataset iterator\n",
    "    #iterator = tqdm(dataloader, ncols=115, desc=description)\n",
    "\n",
    "    # Turn off batch norm, etc. during testing/validation\n",
    "    model = model.train(train_mode)\n",
    "\n",
    "    # Data to print\n",
    "    running_losses, running_predict, running_x, running_y, running_w = [], [], [], [], []\n",
    "\n",
    "    # Loop over all data\n",
    "    with torch.set_grad_enabled(train_mode):\n",
    "        for data in dataloader:\n",
    "            outputs = model(data['image'].to(DEVICE)) # Forward pass\n",
    "            #woah()\n",
    "            if train_mode:\n",
    "                optimizer.zero_grad() # Zero out gradients\n",
    "                loss = loss_func(outputs.double(), torch.cuda.LongTensor(data['needle'][:, 0].to(DEVICE)))\n",
    "                running_losses.append(loss.item())\n",
    "                                \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                \n",
    "            # Update labels and predictions\n",
    "            prediction = outputs.cpu().detach().numpy()\n",
    "            running_predict.extend(prediction)\n",
    "\n",
    "            # Update accuracy\n",
    "            error_x     = np.mean(abs(data[\"needle\"].numpy()[:,0] - prediction[:,0]))\n",
    "            error_y     = -1#np.mean(abs(data[\"needle\"].numpy()[:,1] - prediction[:,1]))\n",
    "            error_w     = -1#np.mean(abs(data[\"needle\"].numpy()[:,2] - prediction[:,2]))\n",
    "            running_x.append(error_x); running_y.append(error_y); running_w.append(error_w)\n",
    "                          \n",
    "#             info_to_show = {'Error x': \"{:.4f}\".format(error_x)}\n",
    "            \n",
    "#             if train_mode:\n",
    "#                 info_to_show['Loss'] = \"{:.5f}\".format(np.mean(running_losses))\n",
    "#             iterator.set_postfix(info_to_show)\n",
    "    \n",
    "    return running_losses, running_predict, running_x, running_y, running_w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## main "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0    Loss: 2.30\t Error_x: 3.07\r"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-9fff8c060e08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Training\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0mLoss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mError_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mError_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mError_w\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me_w\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;31m#epoch(False, \"Validating\", model, dataloader_val)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-77e061a9a504>\u001b[0m in \u001b[0;36mepoch\u001b[0;34m(train_mode, description, model, dataloader, optimizer, loss_func)\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Zero out gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'needle'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                 \u001b[0mrunning_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
     ]
    }
   ],
   "source": [
    "# Create image tranforms\n",
    "transforms_train = torchvision.transforms.Compose([\n",
    "    #torchvision.transforms.ToPILImage(),\n",
    "    torchvision.transforms.Resize((224, 224)),\n",
    "#     torchvision.transforms.RandomCrop((224, 224)),\n",
    "    torchvision.transforms.RandomRotation(30),\n",
    "    torchvision.transforms.ColorJitter(.2, .2, .2, .2), \n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    \n",
    "])\n",
    "transforms_test = torchvision.transforms.Compose([\n",
    "    #torchvision.transforms.ToPILImage(),\n",
    "    torchvision.transforms.Resize((224, 224)),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    \n",
    "])\n",
    "\n",
    "# Create datasets\n",
    "root = '/home/molly/workspace/Surgical_Automation/experiments/needle_master_tools/'\n",
    "dataset_train = pytorch_datasets.NeedleMaster(root, train_split=None, transforms=transforms_train, discrete=True)\n",
    "\n",
    "# Create dataloaders\n",
    "dataloader_train = torch.utils.data.DataLoader(dataset_train, shuffle=True,  batch_size=256,  num_workers=multiprocessing.cpu_count())\n",
    "\n",
    "# Create Model\n",
    "regress_dim = 3\n",
    "n_classes   = 10\n",
    "model       = cnn5(224, n_classes, regress_dim).to(DEVICE)\n",
    "\n",
    "# Create loss function and optimizer\n",
    "optimizer = torch.optim.Adam([p for p in model.parameters() if p.requires_grad], lr=0.0001)\n",
    "loss_func = torch.nn.CrossEntropyLoss().to(DEVICE)\n",
    "\n",
    "# Train + Val\n",
    "Loss, Error_x, Error_y, Error_w = [], [], [], []\n",
    "num_epochs = 20\n",
    "for epoch_idx in range(num_epochs):\n",
    "    loss, pred, e_x, e_y, e_w = epoch(True, \"Training\", model, dataloader_train, optimizer, loss_func)\n",
    "    Loss.extend(loss); Error_x.extend(e_x); Error_y.extend(e_y); Error_w.extend(e_w)\n",
    "    #epoch(False, \"Validating\", model, dataloader_val)\n",
    "    print(\"Epoch: \" + str(epoch_idx) + \"    Loss: \"+ \"%1.2f\" % np.mean(loss) +\"\\t Error_x: \"+ \"%1.2f\" % np.mean(e_x) , end='\\r')\n",
    "# Test\n",
    "#epoch(False, \"Testing\", model, dataloader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()#figsize=(10,5))\n",
    "plt.plot(Loss, 'k--', label='Loss')\n",
    "plt.plot(Error_x, c='r', label='Error x')\n",
    "plt.plot(Error_y, c='b', label='Error y')\n",
    "plt.plot(Error_w, c='g', label='Error w')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,5))\n",
    "plt.plot(np.multiply(Error_x, 1920.0), c='r', label='Error x [pixels]')\n",
    "plt.plot(np.multiply(Error_y, 1080.0), c='b', label='Error y [pixels]')\n",
    "# plt.plot(Error_w*2*3.1415, c='g', label='Error w [radians]')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About this notebook\n",
    "Created on 2/13/2019. Original code from surgical_activity_recognition.py by Mike Peven. Modified by Molly O'Brien. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Footer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(pred, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
